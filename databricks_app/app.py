import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import plotly.express as px
import plotly.graph_objects as go
from typing import Optional
import os
import json

# Page configuration
st.set_page_config(
    page_title="ç”¨æˆ·åé¦ˆç®¡ç†ç³»ç»Ÿ",
    page_icon="ğŸ’¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .feedback-card {
        background-color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
        margin-bottom: 1rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)


class FeedbackDashboard:
    """Feedback Dashboard for Databricks App"""
    
    def __init__(self):
        # Storage backend configuration
        self.storage_backend = os.getenv("STORAGE_BACKEND", "uc")
        
        # Unity Catalog settings
        self.uc_catalog = os.getenv("UC_CATALOG", "dev")
        self.uc_schema = os.getenv("UC_SCHEMA", "inner_feedback")
        self.table_name = os.getenv("TABLE_NAME", "user_feedback")
        self.full_table_name = f"{self.uc_catalog}.{self.uc_schema}.{self.table_name}"
        
        # Databricks Connect settings
        self.databricks_host = os.getenv("DATABRICKS_HOST")
        self.databricks_token = os.getenv("DATABRICKS_TOKEN")
        
        # Local storage settings
        self.local_storage_path = os.getenv("LOCAL_STORAGE_PATH", "./data")
        
        # Initialize connection
        if self.storage_backend == "uc":
            self._init_databricks_connection()
        else:
            os.makedirs(self.local_storage_path, exist_ok=True)
    
    def _init_databricks_connection(self):
        """Initialize Databricks Connect"""
        try:
            from databricks.connect import DatabricksSession
            
            self.spark = DatabricksSession.builder \
                .remote(
                    host=self.databricks_host,
                    token=self.databricks_token
                ) \
                .getOrCreate()
            
            st.success(f"âœ… Connected to Databricks: {self.databricks_host}")
        except Exception as e:
            st.error(f"âŒ Failed to connect to Databricks: {e}")
            st.info("Falling back to local storage")
            self.storage_backend = "local"
            self.spark = None
    
    @st.cache_data(ttl=60)  # Cache for 60 seconds
    def load_feedback_data(_self, days: int = 30) -> pd.DataFrame:
        """Load feedback data from configured storage backend"""
        if _self.storage_backend == "uc":
            return _self._load_from_unity_catalog(days)
        else:
            return _self._load_from_local_storage(days)
    
    def _load_from_unity_catalog(_self, days: int) -> pd.DataFrame:
        """Load feedback data from Unity Catalog"""
        try:
            # Read from Unity Catalog
            df_spark = _self.spark.table(_self.full_table_name)
            
            # Filter by date
            from datetime import timedelta
            cutoff_date = (datetime.now() - timedelta(days=days)).isoformat()
            df_spark = df_spark.filter(df_spark.created_at >= cutoff_date)
            
            # Order by created_at
            df_spark = df_spark.orderBy(df_spark.created_at.desc())
            
            # Convert to Pandas
            df = df_spark.toPandas()
            
            # Convert timestamp columns
            if 'created_at' in df.columns:
                df['created_at'] = pd.to_datetime(df['created_at'])
            if 'processed_at' in df.columns:
                df['processed_at'] = pd.to_datetime(df['processed_at'])
            
            return df
        except Exception as e:
            st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def _load_from_local_storage(_self, days: int) -> pd.DataFrame:
        """Load feedback data from local JSON file"""
        try:
            feedback_file = os.path.join(_self.local_storage_path, "feedbacks.json")
            
            if not os.path.exists(feedback_file):
                return pd.DataFrame()
            
            with open(feedback_file, 'r', encoding='utf-8') as f:
                feedbacks = json.load(f)
            
            if not feedbacks:
                return pd.DataFrame()
            
            # Convert to DataFrame
            df = pd.DataFrame(feedbacks)
            
            # Convert timestamp columns
            if 'created_at' in df.columns:
                df['created_at'] = pd.to_datetime(df['created_at'])
            if 'processed_at' in df.columns:
                df['processed_at'] = pd.to_datetime(df['processed_at'])
            
            # Filter by date
            cutoff_date = datetime.now() - timedelta(days=days)
            df = df[df['created_at'] >= cutoff_date]
            
            # Sort by created_at
            df = df.sort_values('created_at', ascending=False)
            
            return df
        except Exception as e:
            st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def update_feedback_status(self, feedback_id: str, is_processed: bool, notes: str = ""):
        """Update feedback processing status"""
        if self.storage_backend == "uc":
            self._update_in_unity_catalog(feedback_id, is_processed, notes)
        else:
            self._update_in_local_storage(feedback_id, is_processed, notes)
    
    def _update_in_unity_catalog(self, feedback_id: str, is_processed: bool, notes: str):
        """Update feedback in Unity Catalog"""
        try:
            from pyspark.sql.functions import current_timestamp, lit
            
            # Read table
            df = self.spark.table(self.full_table_name)
            
            # Update the specific row
            df_updated = df.withColumn(
                "is_processed",
                lit(is_processed).when(df.feedback_id == feedback_id, lit(is_processed)).otherwise(df.is_processed)
            ).withColumn(
                "processed_at",
                current_timestamp().when(df.feedback_id == feedback_id, current_timestamp()).otherwise(df.processed_at)
            ).withColumn(
                "notes",
                lit(notes).when(df.feedback_id == feedback_id, lit(notes)).otherwise(df.notes)
            )
            
            # Write back to table
            df_updated.write \
                .format("delta") \
                .mode("overwrite") \
                .option("overwriteSchema", "true") \
                .saveAsTable(self.full_table_name)
            
            st.success("çŠ¶æ€æ›´æ–°æˆåŠŸï¼")
            st.cache_data.clear()  # Clear cache to refresh data
        except Exception as e:
            st.error(f"æ›´æ–°å¤±è´¥: {e}")
    
    def _update_in_local_storage(self, feedback_id: str, is_processed: bool, notes: str):
        """Update feedback in local storage"""
        try:
            feedback_file = os.path.join(self.local_storage_path, "feedbacks.json")
            
            with open(feedback_file, 'r', encoding='utf-8') as f:
                feedbacks = json.load(f)
            
            # Update the specific feedback
            for feedback in feedbacks:
                if feedback['feedback_id'] == feedback_id:
                    feedback['is_processed'] = is_processed
                    feedback['processed_at'] = datetime.now().isoformat()
                    feedback['notes'] = notes
                    break
            
            # Save back to file
            with open(feedback_file, 'w', encoding='utf-8') as f:
                json.dump(feedbacks, f, ensure_ascii=False, indent=2)
            
            st.success("çŠ¶æ€æ›´æ–°æˆåŠŸï¼")
            st.cache_data.clear()  # Clear cache to refresh data
        except Exception as e:
            st.error(f"æ›´æ–°å¤±è´¥: {e}")


def render_metrics(df: pd.DataFrame):
    """Render key metrics"""
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="ğŸ“Š æ€»åé¦ˆæ•°",
            value=len(df),
            delta=f"+{len(df[df['created_at'] > datetime.now() - timedelta(days=1)])} ä»Šæ—¥"
        )
    
    with col2:
        bug_count = len(df[df['feedback_type'] == 'bug'])
        st.metric(
            label="ğŸ› Bugåé¦ˆ",
            value=bug_count,
            delta=f"{bug_count/len(df)*100:.1f}%" if len(df) > 0 else "0%"
        )
    
    with col3:
        suggestion_count = len(df[df['feedback_type'] == 'suggestion'])
        st.metric(
            label="ğŸ’¡ å»ºè®®åé¦ˆ",
            value=suggestion_count,
            delta=f"{suggestion_count/len(df)*100:.1f}%" if len(df) > 0 else "0%"
        )
    
    with col4:
        processed_count = len(df[df['is_processed'] == True])
        st.metric(
            label="âœ… å·²å¤„ç†",
            value=processed_count,
            delta=f"{processed_count/len(df)*100:.1f}%" if len(df) > 0 else "0%"
        )


def render_charts(df: pd.DataFrame):
    """Render visualization charts"""
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“ˆ åé¦ˆç±»å‹åˆ†å¸ƒ")
        if not df.empty:
            type_counts = df['feedback_type'].value_counts()
            fig = px.pie(
                values=type_counts.values,
                names=type_counts.index,
                title="åé¦ˆç±»å‹å æ¯”",
                color_discrete_sequence=px.colors.qualitative.Set3
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("æš‚æ— æ•°æ®")
    
    with col2:
        st.subheader("ğŸ“… æ¯æ—¥åé¦ˆè¶‹åŠ¿")
        if not df.empty:
            daily_counts = df.groupby(df['created_at'].dt.date).size().reset_index()
            daily_counts.columns = ['æ—¥æœŸ', 'åé¦ˆæ•°']
            fig = px.line(
                daily_counts,
                x='æ—¥æœŸ',
                y='åé¦ˆæ•°',
                title="æ¯æ—¥åé¦ˆæ•°é‡",
                markers=True
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("æš‚æ— æ•°æ®")


def render_feedback_list(df: pd.DataFrame, dashboard: FeedbackDashboard):
    """Render feedback list with details"""
    st.subheader("ğŸ“ åé¦ˆè¯¦æƒ…åˆ—è¡¨")
    
    # Filters
    col1, col2, col3 = st.columns(3)
    
    with col1:
        feedback_type_filter = st.multiselect(
            "åé¦ˆç±»å‹",
            options=df['feedback_type'].unique().tolist() if not df.empty else [],
            default=df['feedback_type'].unique().tolist() if not df.empty else []
        )
    
    with col2:
        status_filter = st.selectbox(
            "å¤„ç†çŠ¶æ€",
            options=["å…¨éƒ¨", "æœªå¤„ç†", "å·²å¤„ç†"],
            index=0
        )
    
    with col3:
        group_filter = st.multiselect(
            "ç¾¤ç»„",
            options=df['group_name'].unique().tolist() if not df.empty else [],
            default=df['group_name'].unique().tolist() if not df.empty else []
        )
    
    # Apply filters
    filtered_df = df.copy()
    if feedback_type_filter:
        filtered_df = filtered_df[filtered_df['feedback_type'].isin(feedback_type_filter)]
    if status_filter == "æœªå¤„ç†":
        filtered_df = filtered_df[filtered_df['is_processed'] == False]
    elif status_filter == "å·²å¤„ç†":
        filtered_df = filtered_df[filtered_df['is_processed'] == True]
    if group_filter:
        filtered_df = filtered_df[filtered_df['group_name'].isin(group_filter)]
    
    st.write(f"å…± {len(filtered_df)} æ¡åé¦ˆ")
    
    # Display feedback cards
    for idx, row in filtered_df.iterrows():
        with st.expander(
            f"{'âœ…' if row['is_processed'] else 'â³'} "
            f"{row['feedback_type'].upper()} - "
            f"{row['user_name']} - "
            f"{row['created_at'].strftime('%Y-%m-%d %H:%M')}"
        ):
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.markdown(f"**åé¦ˆå†…å®¹ï¼š**")
                st.write(row['feedback_content'])
                st.markdown(f"**ç”¨æˆ·ï¼š** {row['user_name']} ({row['user_id']})")
                st.markdown(f"**ç¾¤ç»„ï¼š** {row['group_name']}")
                st.markdown(f"**æ—¶é—´ï¼š** {row['created_at']}")
                
                if row['notes']:
                    st.markdown(f"**å¤‡æ³¨ï¼š** {row['notes']}")
            
            with col2:
                st.markdown(f"**çŠ¶æ€ï¼š** {'å·²å¤„ç† âœ…' if row['is_processed'] else 'æœªå¤„ç† â³'}")
                
                # Update status form
                with st.form(key=f"form_{row['feedback_id']}"):
                    new_status = st.checkbox(
                        "æ ‡è®°ä¸ºå·²å¤„ç†",
                        value=row['is_processed']
                    )
                    notes = st.text_area(
                        "å¤‡æ³¨",
                        value=row['notes'] if row['notes'] else "",
                        height=100
                    )
                    
                    if st.form_submit_button("æ›´æ–°"):
                        dashboard.update_feedback_status(
                            row['feedback_id'],
                            new_status,
                            notes
                        )
                        st.rerun()


def main():
    """Main application"""
    st.markdown('<h1 class="main-header">ğŸ’¬ ç”¨æˆ·åé¦ˆç®¡ç†ç³»ç»Ÿ</h1>', unsafe_allow_html=True)
    
    # Initialize dashboard
    dashboard = FeedbackDashboard()
    
    # Sidebar
    with st.sidebar:
        st.header("âš™ï¸ è®¾ç½®")
        
        # Time range selector
        days = st.slider(
            "æŸ¥çœ‹æœ€è¿‘å¤©æ•°",
            min_value=1,
            max_value=90,
            value=30,
            step=1
        )
        
        # Refresh button
        if st.button("ğŸ”„ åˆ·æ–°æ•°æ®", use_container_width=True):
            st.cache_data.clear()
            st.rerun()
        
        st.divider()
        
        # Info
        st.info("""
        **åŠŸèƒ½è¯´æ˜ï¼š**
        - ğŸ“Š æŸ¥çœ‹åé¦ˆç»Ÿè®¡
        - ğŸ“ˆ åˆ†æåé¦ˆè¶‹åŠ¿
        - âœ… ç®¡ç†åé¦ˆçŠ¶æ€
        - ğŸ” ç­›é€‰å’Œæœç´¢
        """)
    
    # Load data
    with st.spinner("åŠ è½½æ•°æ®ä¸­..."):
        df = dashboard.load_feedback_data(days)
    
    if df.empty:
        st.warning("æš‚æ— åé¦ˆæ•°æ®")
        st.info("è¯·ç¡®ä¿ä¼ä¸šå¾®ä¿¡ Webhook å·²æ­£ç¡®é…ç½®å¹¶å¼€å§‹æ”¶é›†åé¦ˆæ•°æ®")
        return
    
    # Render dashboard sections
    render_metrics(df)
    st.divider()
    render_charts(df)
    st.divider()
    render_feedback_list(df, dashboard)
    
    # Footer
    st.divider()
    st.markdown("""
    <div style='text-align: center; color: #666; padding: 2rem;'>
        <p>ç”¨æˆ·åé¦ˆç®¡ç†ç³»ç»Ÿ v2.0 | Powered by Databricks & Streamlit</p>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
